{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6scZIRehYVN",
        "outputId": "11cfe3ca-e331-47ad-f0fc-58ee148be00a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('float_format', '{:f}'.format)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "tf.config.list_physical_devices('GPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWtZG2Cbi1uG",
        "outputId": "98955744-87b5-4301-91ca-edcfb1cfbb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/kaggle/ubiquant-market-prediction.zip\n",
            "  inflating: /content/example_sample_submission.csv  \n",
            "  inflating: /content/example_test.csv  \n",
            "  inflating: /content/train.csv      \n",
            "  inflating: /content/ubiquant/__init__.py  \n",
            "  inflating: /content/ubiquant/competition.cpython-37m-x86_64-linux-gnu.so  \n"
          ]
        }
      ],
      "source": [
        "# !unzip /content/drive/MyDrive/kaggle/ubiquant-market-prediction.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9UKFviflhadv"
      },
      "outputs": [],
      "source": [
        "chunk_size = math.pow(10, 6)\n",
        "chunks_path = os.path.join(os.getcwd(), \"drive/MyDrive/kaggle/chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5LuTsBgEVcl"
      },
      "outputs": [],
      "source": [
        "def save_df_chunck(df: pd.DataFrame, index: int):\n",
        "  data_columns = list(filter(lambda i: \"f_\" in i, df.columns.tolist()))\n",
        "  print(f\"Memory usage before df: {df.memory_usage().sum() / math.pow(1024, 2):.2f} MB\")\n",
        "  for i in data_columns:\n",
        "    dtype = df[i].dtype\n",
        "    if \"float\" in str(dtype):\n",
        "      value_min = df[i].min()\n",
        "      value_max = df[i].max()\n",
        "      if value_min > np.finfo(np.float16).min and value_max < np.finfo(np.float16).max:\n",
        "        df[i] = df[i].astype(np.float16)\n",
        "      elif value_min > np.finfo(np.float32).min and value_max < np.finfo(np.float32).max:\n",
        "        df[i] = df[i].astype(np.float32)\n",
        "  print(f\"Memory usage after df: {df.memory_usage().sum() / math.pow(1024, 2):.2f} MB\")\n",
        "  df.to_pickle(os.path.join(chunks_path, f\"chunk_{index}.pkl\"))\n",
        "\n",
        "if not os.path.exists(chunks_path):\n",
        "  os.mkdir(chunks_path)\n",
        "\n",
        "for i, df in enumerate(pd.read_csv(os.path.join(os.getcwd(), \"train.csv\"), chunksize=chunk_size)):\n",
        "  save_df_chunck(df, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-86Vab3GvcL",
        "outputId": "98e240bd-969b-4b68-ffa9-f1d53da12400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pickle5\n",
        "import pickle5 as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnxmqqXYhcCW",
        "outputId": "d0def80b-e63e-48f3-890c-686246462a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_csv memory usage: 1893.4 MB\n",
            "df memory usage: 60.27 MB\n",
            "null values: 0\n"
          ]
        }
      ],
      "source": [
        "dfs = []\n",
        "\n",
        "for i, _ in enumerate(os.listdir(chunks_path)):\n",
        "  path = os.path.join(chunks_path, f\"chunk_{i}.pkl\")\n",
        "  with open(path, \"rb\") as fh:\n",
        "    data = pickle.load(fh)\n",
        "    dfs.append(data)\n",
        "    # dfs.append(pd.read_pickle(os.path.join(chunks_path, f\"chunk_{i}.pkl\")))\n",
        "    \n",
        "train_csv = pd.concat(dfs, axis=0, ignore_index=True)\n",
        "print(f\"train_csv memory usage: {np.round(train_csv.memory_usage().sum() / math.pow(1024,2), 2)} MB\")\n",
        "data_columns = list(filter(lambda i: \"f_\" in i, train_csv.columns.tolist()))\n",
        "df = train_csv[:100000] # processing all rows requires too much system RAM so we'll use 100k rows\n",
        "print(f\"df memory usage: {np.round(df.memory_usage().sum() / math.pow(1024,2), 2)} MB\")\n",
        "print(f\"null values: {df.isna().sum().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "jN92a-XyRQqj",
        "outputId": "f4bed9b5-8f83-4b29-c527-5a9ce3caef95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-360ed0be-77da-4ca0-af63-b000dc3ae30a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f_0</th>\n",
              "      <th>f_1</th>\n",
              "      <th>f_2</th>\n",
              "      <th>f_3</th>\n",
              "      <th>f_4</th>\n",
              "      <th>f_5</th>\n",
              "      <th>f_6</th>\n",
              "      <th>f_7</th>\n",
              "      <th>f_8</th>\n",
              "      <th>f_9</th>\n",
              "      <th>f_10</th>\n",
              "      <th>f_11</th>\n",
              "      <th>f_12</th>\n",
              "      <th>f_13</th>\n",
              "      <th>f_14</th>\n",
              "      <th>f_15</th>\n",
              "      <th>f_16</th>\n",
              "      <th>f_17</th>\n",
              "      <th>f_18</th>\n",
              "      <th>f_19</th>\n",
              "      <th>f_20</th>\n",
              "      <th>f_21</th>\n",
              "      <th>f_22</th>\n",
              "      <th>f_23</th>\n",
              "      <th>f_24</th>\n",
              "      <th>f_25</th>\n",
              "      <th>f_26</th>\n",
              "      <th>f_27</th>\n",
              "      <th>f_28</th>\n",
              "      <th>f_29</th>\n",
              "      <th>f_30</th>\n",
              "      <th>f_31</th>\n",
              "      <th>f_32</th>\n",
              "      <th>f_33</th>\n",
              "      <th>f_34</th>\n",
              "      <th>f_35</th>\n",
              "      <th>f_36</th>\n",
              "      <th>f_37</th>\n",
              "      <th>f_38</th>\n",
              "      <th>f_39</th>\n",
              "      <th>f_40</th>\n",
              "      <th>f_41</th>\n",
              "      <th>f_42</th>\n",
              "      <th>f_43</th>\n",
              "      <th>f_44</th>\n",
              "      <th>f_45</th>\n",
              "      <th>f_46</th>\n",
              "      <th>f_47</th>\n",
              "      <th>f_48</th>\n",
              "      <th>f_49</th>\n",
              "      <th>f_50</th>\n",
              "      <th>f_51</th>\n",
              "      <th>f_52</th>\n",
              "      <th>f_53</th>\n",
              "      <th>f_54</th>\n",
              "      <th>f_55</th>\n",
              "      <th>f_56</th>\n",
              "      <th>f_57</th>\n",
              "      <th>f_58</th>\n",
              "      <th>f_59</th>\n",
              "      <th>f_60</th>\n",
              "      <th>f_61</th>\n",
              "      <th>f_62</th>\n",
              "      <th>f_63</th>\n",
              "      <th>f_64</th>\n",
              "      <th>f_65</th>\n",
              "      <th>f_66</th>\n",
              "      <th>f_67</th>\n",
              "      <th>f_68</th>\n",
              "      <th>f_69</th>\n",
              "      <th>f_70</th>\n",
              "      <th>f_71</th>\n",
              "      <th>f_72</th>\n",
              "      <th>f_73</th>\n",
              "      <th>f_74</th>\n",
              "      <th>f_75</th>\n",
              "      <th>f_76</th>\n",
              "      <th>f_77</th>\n",
              "      <th>f_78</th>\n",
              "      <th>f_79</th>\n",
              "      <th>f_80</th>\n",
              "      <th>f_81</th>\n",
              "      <th>f_82</th>\n",
              "      <th>f_83</th>\n",
              "      <th>f_84</th>\n",
              "      <th>f_85</th>\n",
              "      <th>f_86</th>\n",
              "      <th>f_87</th>\n",
              "      <th>f_88</th>\n",
              "      <th>f_89</th>\n",
              "      <th>f_90</th>\n",
              "      <th>f_91</th>\n",
              "      <th>f_92</th>\n",
              "      <th>f_93</th>\n",
              "      <th>f_94</th>\n",
              "      <th>f_95</th>\n",
              "      <th>f_96</th>\n",
              "      <th>f_97</th>\n",
              "      <th>f_98</th>\n",
              "      <th>f_99</th>\n",
              "      <th>f_100</th>\n",
              "      <th>f_101</th>\n",
              "      <th>f_102</th>\n",
              "      <th>f_103</th>\n",
              "      <th>f_104</th>\n",
              "      <th>f_105</th>\n",
              "      <th>f_106</th>\n",
              "      <th>f_107</th>\n",
              "      <th>f_108</th>\n",
              "      <th>f_109</th>\n",
              "      <th>f_110</th>\n",
              "      <th>f_111</th>\n",
              "      <th>f_112</th>\n",
              "      <th>f_113</th>\n",
              "      <th>f_114</th>\n",
              "      <th>f_115</th>\n",
              "      <th>f_116</th>\n",
              "      <th>f_117</th>\n",
              "      <th>f_118</th>\n",
              "      <th>f_119</th>\n",
              "      <th>f_120</th>\n",
              "      <th>f_121</th>\n",
              "      <th>f_122</th>\n",
              "      <th>f_123</th>\n",
              "      <th>f_124</th>\n",
              "      <th>f_125</th>\n",
              "      <th>f_126</th>\n",
              "      <th>f_127</th>\n",
              "      <th>f_128</th>\n",
              "      <th>f_129</th>\n",
              "      <th>f_130</th>\n",
              "      <th>f_131</th>\n",
              "      <th>f_132</th>\n",
              "      <th>f_133</th>\n",
              "      <th>f_134</th>\n",
              "      <th>f_135</th>\n",
              "      <th>f_136</th>\n",
              "      <th>f_137</th>\n",
              "      <th>f_138</th>\n",
              "      <th>f_139</th>\n",
              "      <th>f_140</th>\n",
              "      <th>f_141</th>\n",
              "      <th>f_142</th>\n",
              "      <th>f_143</th>\n",
              "      <th>f_144</th>\n",
              "      <th>f_145</th>\n",
              "      <th>f_146</th>\n",
              "      <th>f_147</th>\n",
              "      <th>f_148</th>\n",
              "      <th>f_149</th>\n",
              "      <th>f_150</th>\n",
              "      <th>f_151</th>\n",
              "      <th>f_152</th>\n",
              "      <th>f_153</th>\n",
              "      <th>f_154</th>\n",
              "      <th>f_155</th>\n",
              "      <th>f_156</th>\n",
              "      <th>f_157</th>\n",
              "      <th>f_158</th>\n",
              "      <th>f_159</th>\n",
              "      <th>f_160</th>\n",
              "      <th>f_161</th>\n",
              "      <th>f_162</th>\n",
              "      <th>f_163</th>\n",
              "      <th>f_164</th>\n",
              "      <th>f_165</th>\n",
              "      <th>f_166</th>\n",
              "      <th>f_167</th>\n",
              "      <th>f_168</th>\n",
              "      <th>f_169</th>\n",
              "      <th>f_170</th>\n",
              "      <th>f_171</th>\n",
              "      <th>f_172</th>\n",
              "      <th>f_173</th>\n",
              "      <th>f_174</th>\n",
              "      <th>f_175</th>\n",
              "      <th>f_176</th>\n",
              "      <th>f_177</th>\n",
              "      <th>f_178</th>\n",
              "      <th>f_179</th>\n",
              "      <th>f_180</th>\n",
              "      <th>f_181</th>\n",
              "      <th>f_182</th>\n",
              "      <th>f_183</th>\n",
              "      <th>f_184</th>\n",
              "      <th>f_185</th>\n",
              "      <th>f_186</th>\n",
              "      <th>f_187</th>\n",
              "      <th>f_188</th>\n",
              "      <th>f_189</th>\n",
              "      <th>f_190</th>\n",
              "      <th>f_191</th>\n",
              "      <th>f_192</th>\n",
              "      <th>f_193</th>\n",
              "      <th>f_194</th>\n",
              "      <th>f_195</th>\n",
              "      <th>f_196</th>\n",
              "      <th>f_197</th>\n",
              "      <th>f_198</th>\n",
              "      <th>f_199</th>\n",
              "      <th>f_200</th>\n",
              "      <th>f_201</th>\n",
              "      <th>f_202</th>\n",
              "      <th>f_203</th>\n",
              "      <th>f_204</th>\n",
              "      <th>f_205</th>\n",
              "      <th>f_206</th>\n",
              "      <th>f_207</th>\n",
              "      <th>f_208</th>\n",
              "      <th>f_209</th>\n",
              "      <th>f_210</th>\n",
              "      <th>f_211</th>\n",
              "      <th>f_212</th>\n",
              "      <th>f_213</th>\n",
              "      <th>f_214</th>\n",
              "      <th>f_215</th>\n",
              "      <th>f_216</th>\n",
              "      <th>f_217</th>\n",
              "      <th>f_218</th>\n",
              "      <th>f_219</th>\n",
              "      <th>f_220</th>\n",
              "      <th>f_221</th>\n",
              "      <th>f_222</th>\n",
              "      <th>f_223</th>\n",
              "      <th>f_224</th>\n",
              "      <th>f_225</th>\n",
              "      <th>f_226</th>\n",
              "      <th>f_227</th>\n",
              "      <th>f_228</th>\n",
              "      <th>f_229</th>\n",
              "      <th>f_230</th>\n",
              "      <th>f_231</th>\n",
              "      <th>f_232</th>\n",
              "      <th>f_233</th>\n",
              "      <th>f_234</th>\n",
              "      <th>f_235</th>\n",
              "      <th>f_236</th>\n",
              "      <th>f_237</th>\n",
              "      <th>f_238</th>\n",
              "      <th>f_239</th>\n",
              "      <th>f_240</th>\n",
              "      <th>f_241</th>\n",
              "      <th>f_242</th>\n",
              "      <th>f_243</th>\n",
              "      <th>f_244</th>\n",
              "      <th>f_245</th>\n",
              "      <th>f_246</th>\n",
              "      <th>f_247</th>\n",
              "      <th>f_248</th>\n",
              "      <th>f_249</th>\n",
              "      <th>f_250</th>\n",
              "      <th>f_251</th>\n",
              "      <th>f_252</th>\n",
              "      <th>f_253</th>\n",
              "      <th>f_254</th>\n",
              "      <th>f_255</th>\n",
              "      <th>f_256</th>\n",
              "      <th>f_257</th>\n",
              "      <th>f_258</th>\n",
              "      <th>f_259</th>\n",
              "      <th>f_260</th>\n",
              "      <th>f_261</th>\n",
              "      <th>f_262</th>\n",
              "      <th>f_263</th>\n",
              "      <th>f_264</th>\n",
              "      <th>f_265</th>\n",
              "      <th>f_266</th>\n",
              "      <th>f_267</th>\n",
              "      <th>f_268</th>\n",
              "      <th>f_269</th>\n",
              "      <th>f_270</th>\n",
              "      <th>f_271</th>\n",
              "      <th>f_272</th>\n",
              "      <th>f_273</th>\n",
              "      <th>f_274</th>\n",
              "      <th>f_275</th>\n",
              "      <th>f_276</th>\n",
              "      <th>f_277</th>\n",
              "      <th>f_278</th>\n",
              "      <th>f_279</th>\n",
              "      <th>f_280</th>\n",
              "      <th>f_281</th>\n",
              "      <th>f_282</th>\n",
              "      <th>f_283</th>\n",
              "      <th>f_284</th>\n",
              "      <th>f_285</th>\n",
              "      <th>f_286</th>\n",
              "      <th>f_287</th>\n",
              "      <th>f_288</th>\n",
              "      <th>f_289</th>\n",
              "      <th>f_290</th>\n",
              "      <th>f_291</th>\n",
              "      <th>f_292</th>\n",
              "      <th>f_293</th>\n",
              "      <th>f_294</th>\n",
              "      <th>f_295</th>\n",
              "      <th>f_296</th>\n",
              "      <th>f_297</th>\n",
              "      <th>f_298</th>\n",
              "      <th>f_299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.932617</td>\n",
              "      <td>0.113708</td>\n",
              "      <td>-0.402100</td>\n",
              "      <td>0.378418</td>\n",
              "      <td>-0.203979</td>\n",
              "      <td>-0.413574</td>\n",
              "      <td>0.965820</td>\n",
              "      <td>1.230469</td>\n",
              "      <td>0.114807</td>\n",
              "      <td>-2.013672</td>\n",
              "      <td>0.004936</td>\n",
              "      <td>0.284180</td>\n",
              "      <td>0.501953</td>\n",
              "      <td>-0.287842</td>\n",
              "      <td>-1.168945</td>\n",
              "      <td>-0.267334</td>\n",
              "      <td>-0.574219</td>\n",
              "      <td>-0.771973</td>\n",
              "      <td>1.012695</td>\n",
              "      <td>-1.230469</td>\n",
              "      <td>1.786133</td>\n",
              "      <td>-2.089844</td>\n",
              "      <td>0.325684</td>\n",
              "      <td>-0.877930</td>\n",
              "      <td>1.048828</td>\n",
              "      <td>0.131714</td>\n",
              "      <td>-0.349609</td>\n",
              "      <td>-1.813477</td>\n",
              "      <td>0.099243</td>\n",
              "      <td>-0.240967</td>\n",
              "      <td>1.604492</td>\n",
              "      <td>0.003637</td>\n",
              "      <td>-0.901855</td>\n",
              "      <td>0.221558</td>\n",
              "      <td>0.609863</td>\n",
              "      <td>-0.738770</td>\n",
              "      <td>2.097656</td>\n",
              "      <td>-0.914062</td>\n",
              "      <td>-0.293945</td>\n",
              "      <td>-0.037994</td>\n",
              "      <td>0.685547</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.414795</td>\n",
              "      <td>-0.469482</td>\n",
              "      <td>-1.085938</td>\n",
              "      <td>-0.106445</td>\n",
              "      <td>0.059448</td>\n",
              "      <td>0.483154</td>\n",
              "      <td>1.189453</td>\n",
              "      <td>0.506836</td>\n",
              "      <td>0.754395</td>\n",
              "      <td>0.317627</td>\n",
              "      <td>-0.183228</td>\n",
              "      <td>5.164062</td>\n",
              "      <td>0.677246</td>\n",
              "      <td>-0.440674</td>\n",
              "      <td>0.631348</td>\n",
              "      <td>-1.845703</td>\n",
              "      <td>0.227783</td>\n",
              "      <td>0.841309</td>\n",
              "      <td>0.667480</td>\n",
              "      <td>-0.854004</td>\n",
              "      <td>-0.170410</td>\n",
              "      <td>-0.119690</td>\n",
              "      <td>-0.504883</td>\n",
              "      <td>0.662598</td>\n",
              "      <td>1.933594</td>\n",
              "      <td>-0.812500</td>\n",
              "      <td>0.072815</td>\n",
              "      <td>-0.778809</td>\n",
              "      <td>-0.553711</td>\n",
              "      <td>-0.032776</td>\n",
              "      <td>-0.619141</td>\n",
              "      <td>-1.424805</td>\n",
              "      <td>0.148315</td>\n",
              "      <td>0.257812</td>\n",
              "      <td>0.735352</td>\n",
              "      <td>0.563965</td>\n",
              "      <td>-0.272217</td>\n",
              "      <td>1.190430</td>\n",
              "      <td>-0.101379</td>\n",
              "      <td>1.333984</td>\n",
              "      <td>0.191284</td>\n",
              "      <td>0.630859</td>\n",
              "      <td>1.010742</td>\n",
              "      <td>0.161865</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>-0.219482</td>\n",
              "      <td>-0.013069</td>\n",
              "      <td>1.505859</td>\n",
              "      <td>-1.319336</td>\n",
              "      <td>0.448242</td>\n",
              "      <td>-0.635254</td>\n",
              "      <td>-0.075378</td>\n",
              "      <td>1.033203</td>\n",
              "      <td>-0.664062</td>\n",
              "      <td>0.139893</td>\n",
              "      <td>0.186279</td>\n",
              "      <td>0.593262</td>\n",
              "      <td>-0.301514</td>\n",
              "      <td>0.666504</td>\n",
              "      <td>0.713379</td>\n",
              "      <td>1.020508</td>\n",
              "      <td>0.879883</td>\n",
              "      <td>-1.096680</td>\n",
              "      <td>-0.211060</td>\n",
              "      <td>-0.117493</td>\n",
              "      <td>-0.778809</td>\n",
              "      <td>0.065979</td>\n",
              "      <td>0.229736</td>\n",
              "      <td>0.435303</td>\n",
              "      <td>1.233398</td>\n",
              "      <td>-0.865723</td>\n",
              "      <td>0.062347</td>\n",
              "      <td>0.382324</td>\n",
              "      <td>-1.315430</td>\n",
              "      <td>0.786621</td>\n",
              "      <td>0.770508</td>\n",
              "      <td>-0.871094</td>\n",
              "      <td>0.583496</td>\n",
              "      <td>0.115601</td>\n",
              "      <td>0.209595</td>\n",
              "      <td>0.325439</td>\n",
              "      <td>0.469238</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.731445</td>\n",
              "      <td>-0.249512</td>\n",
              "      <td>-0.050568</td>\n",
              "      <td>-1.232422</td>\n",
              "      <td>-0.790527</td>\n",
              "      <td>0.493408</td>\n",
              "      <td>0.357910</td>\n",
              "      <td>-0.381592</td>\n",
              "      <td>0.176392</td>\n",
              "      <td>0.748047</td>\n",
              "      <td>-0.741699</td>\n",
              "      <td>0.089661</td>\n",
              "      <td>1.080078</td>\n",
              "      <td>1.137695</td>\n",
              "      <td>1.199219</td>\n",
              "      <td>0.030609</td>\n",
              "      <td>-0.356201</td>\n",
              "      <td>0.247803</td>\n",
              "      <td>1.395508</td>\n",
              "      <td>0.961914</td>\n",
              "      <td>0.078125</td>\n",
              "      <td>-1.163086</td>\n",
              "      <td>0.707520</td>\n",
              "      <td>0.256104</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.329102</td>\n",
              "      <td>0.196045</td>\n",
              "      <td>0.653320</td>\n",
              "      <td>0.069214</td>\n",
              "      <td>0.907715</td>\n",
              "      <td>-0.350586</td>\n",
              "      <td>-1.170898</td>\n",
              "      <td>0.659180</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.482910</td>\n",
              "      <td>-0.094910</td>\n",
              "      <td>0.317383</td>\n",
              "      <td>0.126831</td>\n",
              "      <td>0.892090</td>\n",
              "      <td>-1.199219</td>\n",
              "      <td>-0.315430</td>\n",
              "      <td>0.704102</td>\n",
              "      <td>-0.017700</td>\n",
              "      <td>-0.513184</td>\n",
              "      <td>-0.362549</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.265625</td>\n",
              "      <td>0.360107</td>\n",
              "      <td>0.054474</td>\n",
              "      <td>1.639648</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.876953</td>\n",
              "      <td>0.368164</td>\n",
              "      <td>0.991211</td>\n",
              "      <td>-1.224609</td>\n",
              "      <td>-1.208984</td>\n",
              "      <td>-0.879883</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>0.693359</td>\n",
              "      <td>0.307129</td>\n",
              "      <td>0.143799</td>\n",
              "      <td>0.728027</td>\n",
              "      <td>1.220703</td>\n",
              "      <td>-0.939941</td>\n",
              "      <td>-0.106934</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.569336</td>\n",
              "      <td>0.187866</td>\n",
              "      <td>-0.386475</td>\n",
              "      <td>-0.452393</td>\n",
              "      <td>0.269775</td>\n",
              "      <td>-0.565430</td>\n",
              "      <td>-0.262207</td>\n",
              "      <td>-1.473633</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428223</td>\n",
              "      <td>1.740234</td>\n",
              "      <td>0.941406</td>\n",
              "      <td>-0.729980</td>\n",
              "      <td>-0.533203</td>\n",
              "      <td>-0.983398</td>\n",
              "      <td>-0.043152</td>\n",
              "      <td>-0.225952</td>\n",
              "      <td>-0.008301</td>\n",
              "      <td>-0.447998</td>\n",
              "      <td>0.551270</td>\n",
              "      <td>-0.153076</td>\n",
              "      <td>-2.292969</td>\n",
              "      <td>0.186646</td>\n",
              "      <td>-0.443115</td>\n",
              "      <td>0.121216</td>\n",
              "      <td>0.787598</td>\n",
              "      <td>1.996094</td>\n",
              "      <td>-1.286133</td>\n",
              "      <td>-0.157227</td>\n",
              "      <td>1.019531</td>\n",
              "      <td>0.693359</td>\n",
              "      <td>0.797363</td>\n",
              "      <td>-0.192627</td>\n",
              "      <td>0.222778</td>\n",
              "      <td>0.921387</td>\n",
              "      <td>-0.171387</td>\n",
              "      <td>0.021652</td>\n",
              "      <td>1.153320</td>\n",
              "      <td>0.689941</td>\n",
              "      <td>3.251953</td>\n",
              "      <td>0.992188</td>\n",
              "      <td>-0.779785</td>\n",
              "      <td>-0.546387</td>\n",
              "      <td>-0.379150</td>\n",
              "      <td>1.896484</td>\n",
              "      <td>-0.732422</td>\n",
              "      <td>-0.113770</td>\n",
              "      <td>1.127930</td>\n",
              "      <td>-0.007927</td>\n",
              "      <td>0.122314</td>\n",
              "      <td>0.444580</td>\n",
              "      <td>0.485840</td>\n",
              "      <td>-2.302734</td>\n",
              "      <td>0.392822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.779297</td>\n",
              "      <td>-0.893555</td>\n",
              "      <td>0.055939</td>\n",
              "      <td>0.201416</td>\n",
              "      <td>-0.338135</td>\n",
              "      <td>1.278320</td>\n",
              "      <td>1.367188</td>\n",
              "      <td>0.525391</td>\n",
              "      <td>-0.055664</td>\n",
              "      <td>0.145264</td>\n",
              "      <td>0.346924</td>\n",
              "      <td>-0.824219</td>\n",
              "      <td>-1.306641</td>\n",
              "      <td>-1.158203</td>\n",
              "      <td>0.709473</td>\n",
              "      <td>-0.031891</td>\n",
              "      <td>-1.020508</td>\n",
              "      <td>-1.291016</td>\n",
              "      <td>0.038666</td>\n",
              "      <td>0.187134</td>\n",
              "      <td>-0.680176</td>\n",
              "      <td>0.900391</td>\n",
              "      <td>-0.924805</td>\n",
              "      <td>-1.057617</td>\n",
              "      <td>-0.167114</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.281250</td>\n",
              "      <td>0.258789</td>\n",
              "      <td>-0.237915</td>\n",
              "      <td>-0.742188</td>\n",
              "      <td>-0.324707</td>\n",
              "      <td>0.992676</td>\n",
              "      <td>0.961426</td>\n",
              "      <td>-0.025604</td>\n",
              "      <td>-0.006260</td>\n",
              "      <td>0.473633</td>\n",
              "      <td>0.040131</td>\n",
              "      <td>0.453613</td>\n",
              "      <td>-1.597656</td>\n",
              "      <td>0.301758</td>\n",
              "      <td>0.157471</td>\n",
              "      <td>0.416748</td>\n",
              "      <td>1.505859</td>\n",
              "      <td>0.365967</td>\n",
              "      <td>-1.095703</td>\n",
              "      <td>0.200073</td>\n",
              "      <td>0.819336</td>\n",
              "      <td>0.941406</td>\n",
              "      <td>-0.086792</td>\n",
              "      <td>-1.086914</td>\n",
              "      <td>-1.044922</td>\n",
              "      <td>-0.287598</td>\n",
              "      <td>0.321533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.811035</td>\n",
              "      <td>-0.514160</td>\n",
              "      <td>0.742188</td>\n",
              "      <td>-0.616699</td>\n",
              "      <td>-0.194214</td>\n",
              "      <td>1.771484</td>\n",
              "      <td>1.427734</td>\n",
              "      <td>1.133789</td>\n",
              "      <td>0.114807</td>\n",
              "      <td>-0.219238</td>\n",
              "      <td>-0.351807</td>\n",
              "      <td>0.846680</td>\n",
              "      <td>0.440186</td>\n",
              "      <td>0.499756</td>\n",
              "      <td>0.893066</td>\n",
              "      <td>-0.010216</td>\n",
              "      <td>-0.681641</td>\n",
              "      <td>1.253906</td>\n",
              "      <td>-1.027344</td>\n",
              "      <td>-1.690430</td>\n",
              "      <td>0.011154</td>\n",
              "      <td>0.875488</td>\n",
              "      <td>0.325684</td>\n",
              "      <td>-0.458252</td>\n",
              "      <td>-1.797852</td>\n",
              "      <td>-0.300293</td>\n",
              "      <td>0.584961</td>\n",
              "      <td>0.551270</td>\n",
              "      <td>0.806641</td>\n",
              "      <td>1.235352</td>\n",
              "      <td>-0.984863</td>\n",
              "      <td>-1.084961</td>\n",
              "      <td>3.162109</td>\n",
              "      <td>0.211060</td>\n",
              "      <td>-2.656250</td>\n",
              "      <td>-0.177002</td>\n",
              "      <td>0.486572</td>\n",
              "      <td>1.237305</td>\n",
              "      <td>-0.447510</td>\n",
              "      <td>-0.403564</td>\n",
              "      <td>-0.769531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.516602</td>\n",
              "      <td>-1.307617</td>\n",
              "      <td>-0.092407</td>\n",
              "      <td>0.971191</td>\n",
              "      <td>-0.069336</td>\n",
              "      <td>-0.963379</td>\n",
              "      <td>-0.840820</td>\n",
              "      <td>0.438965</td>\n",
              "      <td>0.317139</td>\n",
              "      <td>0.138550</td>\n",
              "      <td>-1.167969</td>\n",
              "      <td>0.082336</td>\n",
              "      <td>1.059570</td>\n",
              "      <td>-0.440674</td>\n",
              "      <td>0.631348</td>\n",
              "      <td>0.495117</td>\n",
              "      <td>1.163086</td>\n",
              "      <td>0.453369</td>\n",
              "      <td>0.631836</td>\n",
              "      <td>-0.651855</td>\n",
              "      <td>-0.170410</td>\n",
              "      <td>-0.119690</td>\n",
              "      <td>0.186157</td>\n",
              "      <td>-0.292480</td>\n",
              "      <td>-0.549805</td>\n",
              "      <td>-1.629883</td>\n",
              "      <td>0.902832</td>\n",
              "      <td>0.509766</td>\n",
              "      <td>0.377441</td>\n",
              "      <td>0.052094</td>\n",
              "      <td>-0.763184</td>\n",
              "      <td>-1.307617</td>\n",
              "      <td>0.148315</td>\n",
              "      <td>0.777832</td>\n",
              "      <td>-0.383301</td>\n",
              "      <td>-0.099487</td>\n",
              "      <td>-0.119995</td>\n",
              "      <td>1.466797</td>\n",
              "      <td>-0.255371</td>\n",
              "      <td>0.136353</td>\n",
              "      <td>0.191284</td>\n",
              "      <td>-0.404541</td>\n",
              "      <td>-1.220703</td>\n",
              "      <td>-1.442383</td>\n",
              "      <td>1.088867</td>\n",
              "      <td>-0.479248</td>\n",
              "      <td>0.476318</td>\n",
              "      <td>-1.238281</td>\n",
              "      <td>0.139160</td>\n",
              "      <td>-1.238281</td>\n",
              "      <td>0.277344</td>\n",
              "      <td>0.925781</td>\n",
              "      <td>-0.666016</td>\n",
              "      <td>-0.496582</td>\n",
              "      <td>-1.344727</td>\n",
              "      <td>-0.514160</td>\n",
              "      <td>-0.081726</td>\n",
              "      <td>-0.301514</td>\n",
              "      <td>-0.918945</td>\n",
              "      <td>-0.051697</td>\n",
              "      <td>1.020508</td>\n",
              "      <td>0.746582</td>\n",
              "      <td>0.911621</td>\n",
              "      <td>-0.343994</td>\n",
              "      <td>-0.948242</td>\n",
              "      <td>-0.778809</td>\n",
              "      <td>0.065979</td>\n",
              "      <td>-0.229980</td>\n",
              "      <td>-0.153564</td>\n",
              "      <td>-0.722168</td>\n",
              "      <td>-0.947266</td>\n",
              "      <td>1.321289</td>\n",
              "      <td>-0.075256</td>\n",
              "      <td>0.997070</td>\n",
              "      <td>-0.137695</td>\n",
              "      <td>0.724121</td>\n",
              "      <td>-0.722168</td>\n",
              "      <td>0.541992</td>\n",
              "      <td>0.730469</td>\n",
              "      <td>0.478027</td>\n",
              "      <td>-0.662109</td>\n",
              "      <td>0.605957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.280518</td>\n",
              "      <td>0.781738</td>\n",
              "      <td>-0.140503</td>\n",
              "      <td>0.324951</td>\n",
              "      <td>0.540527</td>\n",
              "      <td>-0.686523</td>\n",
              "      <td>0.388916</td>\n",
              "      <td>-1.551758</td>\n",
              "      <td>-0.662109</td>\n",
              "      <td>0.312256</td>\n",
              "      <td>-1.089844</td>\n",
              "      <td>0.530762</td>\n",
              "      <td>-0.730469</td>\n",
              "      <td>-0.878906</td>\n",
              "      <td>-1.139648</td>\n",
              "      <td>-1.336914</td>\n",
              "      <td>0.804688</td>\n",
              "      <td>0.247803</td>\n",
              "      <td>-1.292969</td>\n",
              "      <td>-0.892578</td>\n",
              "      <td>0.078125</td>\n",
              "      <td>0.023346</td>\n",
              "      <td>-0.957031</td>\n",
              "      <td>-0.042419</td>\n",
              "      <td>-0.195312</td>\n",
              "      <td>0.329102</td>\n",
              "      <td>-0.181152</td>\n",
              "      <td>0.653320</td>\n",
              "      <td>0.069214</td>\n",
              "      <td>-0.818848</td>\n",
              "      <td>0.308838</td>\n",
              "      <td>0.894531</td>\n",
              "      <td>0.010490</td>\n",
              "      <td>0.904297</td>\n",
              "      <td>1.197266</td>\n",
              "      <td>1.052734</td>\n",
              "      <td>0.915039</td>\n",
              "      <td>-1.083984</td>\n",
              "      <td>-0.541992</td>\n",
              "      <td>-0.898926</td>\n",
              "      <td>-0.043518</td>\n",
              "      <td>-0.375732</td>\n",
              "      <td>0.167969</td>\n",
              "      <td>0.552246</td>\n",
              "      <td>0.772949</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.250000</td>\n",
              "      <td>0.409912</td>\n",
              "      <td>-0.695312</td>\n",
              "      <td>1.639648</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.876953</td>\n",
              "      <td>-1.523438</td>\n",
              "      <td>-0.526855</td>\n",
              "      <td>-0.071045</td>\n",
              "      <td>-0.404785</td>\n",
              "      <td>0.269531</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>-0.309326</td>\n",
              "      <td>-1.067383</td>\n",
              "      <td>1.087891</td>\n",
              "      <td>-1.145508</td>\n",
              "      <td>-0.025330</td>\n",
              "      <td>-0.398438</td>\n",
              "      <td>-1.173828</td>\n",
              "      <td>0.427002</td>\n",
              "      <td>0.043945</td>\n",
              "      <td>0.510742</td>\n",
              "      <td>1.408203</td>\n",
              "      <td>-0.718750</td>\n",
              "      <td>2.076172</td>\n",
              "      <td>-0.507812</td>\n",
              "      <td>0.942383</td>\n",
              "      <td>1.028320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.050781</td>\n",
              "      <td>-1.009766</td>\n",
              "      <td>0.480713</td>\n",
              "      <td>-1.363281</td>\n",
              "      <td>-0.358398</td>\n",
              "      <td>0.084900</td>\n",
              "      <td>-0.012634</td>\n",
              "      <td>-1.496094</td>\n",
              "      <td>-1.260742</td>\n",
              "      <td>-0.452148</td>\n",
              "      <td>-0.253418</td>\n",
              "      <td>-1.107422</td>\n",
              "      <td>0.492188</td>\n",
              "      <td>0.727051</td>\n",
              "      <td>0.400635</td>\n",
              "      <td>-2.302734</td>\n",
              "      <td>1.443359</td>\n",
              "      <td>-0.231445</td>\n",
              "      <td>0.777344</td>\n",
              "      <td>1.995117</td>\n",
              "      <td>-0.593750</td>\n",
              "      <td>0.737793</td>\n",
              "      <td>-0.841797</td>\n",
              "      <td>-0.191528</td>\n",
              "      <td>0.222778</td>\n",
              "      <td>0.872559</td>\n",
              "      <td>0.611328</td>\n",
              "      <td>-0.113159</td>\n",
              "      <td>1.153320</td>\n",
              "      <td>0.866211</td>\n",
              "      <td>-0.269775</td>\n",
              "      <td>-0.078003</td>\n",
              "      <td>-0.332764</td>\n",
              "      <td>-0.546387</td>\n",
              "      <td>-0.678711</td>\n",
              "      <td>-0.434082</td>\n",
              "      <td>-0.584473</td>\n",
              "      <td>0.332031</td>\n",
              "      <td>-0.646973</td>\n",
              "      <td>-0.176514</td>\n",
              "      <td>0.122314</td>\n",
              "      <td>-0.068176</td>\n",
              "      <td>-0.868164</td>\n",
              "      <td>0.844727</td>\n",
              "      <td>0.863281</td>\n",
              "      <td>1.179688</td>\n",
              "      <td>-0.049469</td>\n",
              "      <td>0.484863</td>\n",
              "      <td>-0.050537</td>\n",
              "      <td>-0.491943</td>\n",
              "      <td>-0.164429</td>\n",
              "      <td>0.133667</td>\n",
              "      <td>-0.952637</td>\n",
              "      <td>-0.387451</td>\n",
              "      <td>0.090637</td>\n",
              "      <td>-0.811035</td>\n",
              "      <td>-0.821289</td>\n",
              "      <td>-0.546875</td>\n",
              "      <td>-0.067871</td>\n",
              "      <td>-0.767090</td>\n",
              "      <td>-0.015457</td>\n",
              "      <td>-0.158325</td>\n",
              "      <td>0.980469</td>\n",
              "      <td>0.799316</td>\n",
              "      <td>0.798340</td>\n",
              "      <td>-0.633301</td>\n",
              "      <td>0.779785</td>\n",
              "      <td>0.171265</td>\n",
              "      <td>1.166016</td>\n",
              "      <td>0.590820</td>\n",
              "      <td>0.118530</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.650879</td>\n",
              "      <td>0.852051</td>\n",
              "      <td>0.086182</td>\n",
              "      <td>1.135742</td>\n",
              "      <td>0.299072</td>\n",
              "      <td>-1.583008</td>\n",
              "      <td>-0.481934</td>\n",
              "      <td>0.532227</td>\n",
              "      <td>0.226685</td>\n",
              "      <td>-0.894531</td>\n",
              "      <td>-0.514648</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.884277</td>\n",
              "      <td>-0.557617</td>\n",
              "      <td>-0.875488</td>\n",
              "      <td>-0.156128</td>\n",
              "      <td>0.537109</td>\n",
              "      <td>-0.154175</td>\n",
              "      <td>0.912598</td>\n",
              "      <td>-0.734375</td>\n",
              "      <td>0.819336</td>\n",
              "      <td>0.941406</td>\n",
              "      <td>-0.387695</td>\n",
              "      <td>-1.086914</td>\n",
              "      <td>-0.929688</td>\n",
              "      <td>-0.974121</td>\n",
              "      <td>-0.343506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.394043</td>\n",
              "      <td>0.615723</td>\n",
              "      <td>0.567871</td>\n",
              "      <td>-0.607910</td>\n",
              "      <td>0.068909</td>\n",
              "      <td>-1.083008</td>\n",
              "      <td>0.979492</td>\n",
              "      <td>-1.125977</td>\n",
              "      <td>0.114807</td>\n",
              "      <td>-1.035156</td>\n",
              "      <td>0.465088</td>\n",
              "      <td>0.150879</td>\n",
              "      <td>-0.044006</td>\n",
              "      <td>0.091248</td>\n",
              "      <td>-1.168945</td>\n",
              "      <td>-0.451904</td>\n",
              "      <td>-0.467285</td>\n",
              "      <td>0.095276</td>\n",
              "      <td>1.140625</td>\n",
              "      <td>-0.166870</td>\n",
              "      <td>-0.007294</td>\n",
              "      <td>-0.449463</td>\n",
              "      <td>0.325684</td>\n",
              "      <td>-0.682617</td>\n",
              "      <td>0.016266</td>\n",
              "      <td>0.026123</td>\n",
              "      <td>-0.547363</td>\n",
              "      <td>0.551270</td>\n",
              "      <td>-0.261475</td>\n",
              "      <td>-0.169678</td>\n",
              "      <td>0.857422</td>\n",
              "      <td>-0.098450</td>\n",
              "      <td>-0.860352</td>\n",
              "      <td>0.180176</td>\n",
              "      <td>0.609863</td>\n",
              "      <td>0.524902</td>\n",
              "      <td>-0.400391</td>\n",
              "      <td>0.751465</td>\n",
              "      <td>-0.287598</td>\n",
              "      <td>0.568359</td>\n",
              "      <td>0.829102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.253174</td>\n",
              "      <td>-0.235474</td>\n",
              "      <td>0.500977</td>\n",
              "      <td>-0.655762</td>\n",
              "      <td>-0.750977</td>\n",
              "      <td>0.664062</td>\n",
              "      <td>1.189453</td>\n",
              "      <td>1.087891</td>\n",
              "      <td>0.859375</td>\n",
              "      <td>-0.133545</td>\n",
              "      <td>-0.183228</td>\n",
              "      <td>0.082336</td>\n",
              "      <td>-0.060181</td>\n",
              "      <td>-0.440674</td>\n",
              "      <td>0.631348</td>\n",
              "      <td>-0.026169</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>-0.855957</td>\n",
              "      <td>1.052734</td>\n",
              "      <td>-0.526855</td>\n",
              "      <td>-0.170410</td>\n",
              "      <td>-0.119690</td>\n",
              "      <td>0.038177</td>\n",
              "      <td>0.309814</td>\n",
              "      <td>-0.549805</td>\n",
              "      <td>1.638672</td>\n",
              "      <td>-0.476562</td>\n",
              "      <td>-0.909180</td>\n",
              "      <td>-0.544922</td>\n",
              "      <td>-0.546387</td>\n",
              "      <td>0.163452</td>\n",
              "      <td>1.748047</td>\n",
              "      <td>0.148315</td>\n",
              "      <td>0.365234</td>\n",
              "      <td>0.342773</td>\n",
              "      <td>-0.813965</td>\n",
              "      <td>-0.046417</td>\n",
              "      <td>-0.484863</td>\n",
              "      <td>-0.270264</td>\n",
              "      <td>0.136353</td>\n",
              "      <td>-1.441406</td>\n",
              "      <td>-0.079163</td>\n",
              "      <td>-0.530762</td>\n",
              "      <td>0.130981</td>\n",
              "      <td>0.221558</td>\n",
              "      <td>-0.228882</td>\n",
              "      <td>0.700195</td>\n",
              "      <td>0.023468</td>\n",
              "      <td>0.269287</td>\n",
              "      <td>0.039825</td>\n",
              "      <td>-0.963867</td>\n",
              "      <td>-0.790039</td>\n",
              "      <td>0.693359</td>\n",
              "      <td>-0.593750</td>\n",
              "      <td>0.295166</td>\n",
              "      <td>-0.096008</td>\n",
              "      <td>0.447754</td>\n",
              "      <td>-0.301514</td>\n",
              "      <td>1.039062</td>\n",
              "      <td>-0.291748</td>\n",
              "      <td>1.020508</td>\n",
              "      <td>0.529297</td>\n",
              "      <td>-1.096680</td>\n",
              "      <td>0.150757</td>\n",
              "      <td>-0.074646</td>\n",
              "      <td>1.254883</td>\n",
              "      <td>0.065979</td>\n",
              "      <td>0.869141</td>\n",
              "      <td>0.518066</td>\n",
              "      <td>0.494385</td>\n",
              "      <td>-0.028580</td>\n",
              "      <td>-0.478271</td>\n",
              "      <td>-0.733887</td>\n",
              "      <td>0.200806</td>\n",
              "      <td>-0.174561</td>\n",
              "      <td>-0.255127</td>\n",
              "      <td>0.558594</td>\n",
              "      <td>0.586426</td>\n",
              "      <td>-2.177734</td>\n",
              "      <td>-0.765137</td>\n",
              "      <td>0.200317</td>\n",
              "      <td>0.346436</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.065796</td>\n",
              "      <td>-0.298340</td>\n",
              "      <td>-0.040955</td>\n",
              "      <td>-0.875977</td>\n",
              "      <td>-0.625000</td>\n",
              "      <td>1.005859</td>\n",
              "      <td>-0.471924</td>\n",
              "      <td>0.788574</td>\n",
              "      <td>-0.547363</td>\n",
              "      <td>-0.039612</td>\n",
              "      <td>-0.885254</td>\n",
              "      <td>-0.161743</td>\n",
              "      <td>0.186157</td>\n",
              "      <td>1.137695</td>\n",
              "      <td>0.052643</td>\n",
              "      <td>0.323242</td>\n",
              "      <td>1.156250</td>\n",
              "      <td>0.247803</td>\n",
              "      <td>0.859375</td>\n",
              "      <td>0.873047</td>\n",
              "      <td>0.078125</td>\n",
              "      <td>-0.250977</td>\n",
              "      <td>-0.418213</td>\n",
              "      <td>0.927246</td>\n",
              "      <td>0.648438</td>\n",
              "      <td>0.329102</td>\n",
              "      <td>0.015572</td>\n",
              "      <td>0.653320</td>\n",
              "      <td>0.069214</td>\n",
              "      <td>0.907715</td>\n",
              "      <td>-0.642578</td>\n",
              "      <td>-1.170898</td>\n",
              "      <td>-0.100586</td>\n",
              "      <td>0.122498</td>\n",
              "      <td>-0.247559</td>\n",
              "      <td>0.694336</td>\n",
              "      <td>-0.167358</td>\n",
              "      <td>1.062500</td>\n",
              "      <td>0.718262</td>\n",
              "      <td>-0.844238</td>\n",
              "      <td>-0.105347</td>\n",
              "      <td>0.166626</td>\n",
              "      <td>-0.375732</td>\n",
              "      <td>-0.513184</td>\n",
              "      <td>-0.393555</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.596191</td>\n",
              "      <td>-0.446289</td>\n",
              "      <td>-0.115051</td>\n",
              "      <td>-0.709961</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.431641</td>\n",
              "      <td>-0.577637</td>\n",
              "      <td>-0.418457</td>\n",
              "      <td>-0.515137</td>\n",
              "      <td>-0.307617</td>\n",
              "      <td>-0.283691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>-0.393799</td>\n",
              "      <td>0.288086</td>\n",
              "      <td>0.366455</td>\n",
              "      <td>0.103333</td>\n",
              "      <td>-0.098328</td>\n",
              "      <td>0.133911</td>\n",
              "      <td>0.212280</td>\n",
              "      <td>0.384521</td>\n",
              "      <td>0.501465</td>\n",
              "      <td>-0.339355</td>\n",
              "      <td>0.010094</td>\n",
              "      <td>-0.007168</td>\n",
              "      <td>-1.117188</td>\n",
              "      <td>-0.564941</td>\n",
              "      <td>0.672852</td>\n",
              "      <td>-0.775879</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.070007</td>\n",
              "      <td>0.883301</td>\n",
              "      <td>0.579102</td>\n",
              "      <td>0.942871</td>\n",
              "      <td>-0.793457</td>\n",
              "      <td>-0.955078</td>\n",
              "      <td>0.131836</td>\n",
              "      <td>-0.546875</td>\n",
              "      <td>0.905273</td>\n",
              "      <td>-0.452148</td>\n",
              "      <td>0.675293</td>\n",
              "      <td>-0.036041</td>\n",
              "      <td>-1.169922</td>\n",
              "      <td>-0.167603</td>\n",
              "      <td>-0.274414</td>\n",
              "      <td>0.114014</td>\n",
              "      <td>0.103210</td>\n",
              "      <td>0.071045</td>\n",
              "      <td>-1.286133</td>\n",
              "      <td>-0.407959</td>\n",
              "      <td>0.137207</td>\n",
              "      <td>-0.399414</td>\n",
              "      <td>0.335693</td>\n",
              "      <td>-0.149292</td>\n",
              "      <td>0.222778</td>\n",
              "      <td>0.156128</td>\n",
              "      <td>-0.171387</td>\n",
              "      <td>0.258301</td>\n",
              "      <td>1.153320</td>\n",
              "      <td>-0.964355</td>\n",
              "      <td>-0.269775</td>\n",
              "      <td>-0.654297</td>\n",
              "      <td>0.180542</td>\n",
              "      <td>-1.220703</td>\n",
              "      <td>0.457520</td>\n",
              "      <td>-0.461182</td>\n",
              "      <td>-0.976562</td>\n",
              "      <td>0.147339</td>\n",
              "      <td>0.060364</td>\n",
              "      <td>-0.271729</td>\n",
              "      <td>0.122314</td>\n",
              "      <td>1.450195</td>\n",
              "      <td>1.163086</td>\n",
              "      <td>0.402588</td>\n",
              "      <td>-0.101135</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019119</td>\n",
              "      <td>0.523438</td>\n",
              "      <td>-0.005413</td>\n",
              "      <td>-0.092407</td>\n",
              "      <td>-0.001884</td>\n",
              "      <td>0.259277</td>\n",
              "      <td>0.507324</td>\n",
              "      <td>0.202515</td>\n",
              "      <td>-0.370850</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.257080</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>-0.662598</td>\n",
              "      <td>1.066406</td>\n",
              "      <td>-0.528320</td>\n",
              "      <td>0.189453</td>\n",
              "      <td>-1.020508</td>\n",
              "      <td>0.169678</td>\n",
              "      <td>-0.911133</td>\n",
              "      <td>-0.222046</td>\n",
              "      <td>0.536621</td>\n",
              "      <td>-0.161743</td>\n",
              "      <td>-0.114319</td>\n",
              "      <td>0.433350</td>\n",
              "      <td>-0.207153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098938</td>\n",
              "      <td>-0.725098</td>\n",
              "      <td>-0.388184</td>\n",
              "      <td>0.062622</td>\n",
              "      <td>0.260254</td>\n",
              "      <td>0.980957</td>\n",
              "      <td>0.899414</td>\n",
              "      <td>-0.315430</td>\n",
              "      <td>0.150146</td>\n",
              "      <td>0.245605</td>\n",
              "      <td>-1.429688</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.033508</td>\n",
              "      <td>-0.147095</td>\n",
              "      <td>-0.087524</td>\n",
              "      <td>0.098450</td>\n",
              "      <td>-0.528809</td>\n",
              "      <td>-0.138062</td>\n",
              "      <td>0.912598</td>\n",
              "      <td>-0.551758</td>\n",
              "      <td>-1.220703</td>\n",
              "      <td>-1.060547</td>\n",
              "      <td>-0.219116</td>\n",
              "      <td>-1.086914</td>\n",
              "      <td>-0.612305</td>\n",
              "      <td>-0.113953</td>\n",
              "      <td>0.243652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-360ed0be-77da-4ca0-af63-b000dc3ae30a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-360ed0be-77da-4ca0-af63-b000dc3ae30a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-360ed0be-77da-4ca0-af63-b000dc3ae30a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       f_0       f_1       f_2       f_3       f_4       f_5      f_6  \\\n",
              "0 0.932617  0.113708 -0.402100  0.378418 -0.203979 -0.413574 0.965820   \n",
              "1 0.811035 -0.514160  0.742188 -0.616699 -0.194214  1.771484 1.427734   \n",
              "2 0.394043  0.615723  0.567871 -0.607910  0.068909 -1.083008 0.979492   \n",
              "\n",
              "        f_7      f_8       f_9      f_10     f_11      f_12      f_13  \\\n",
              "0  1.230469 0.114807 -2.013672  0.004936 0.284180  0.501953 -0.287842   \n",
              "1  1.133789 0.114807 -0.219238 -0.351807 0.846680  0.440186  0.499756   \n",
              "2 -1.125977 0.114807 -1.035156  0.465088 0.150879 -0.044006  0.091248   \n",
              "\n",
              "       f_14      f_15      f_16      f_17      f_18      f_19      f_20  \\\n",
              "0 -1.168945 -0.267334 -0.574219 -0.771973  1.012695 -1.230469  1.786133   \n",
              "1  0.893066 -0.010216 -0.681641  1.253906 -1.027344 -1.690430  0.011154   \n",
              "2 -1.168945 -0.451904 -0.467285  0.095276  1.140625 -0.166870 -0.007294   \n",
              "\n",
              "       f_21     f_22      f_23      f_24      f_25      f_26      f_27  \\\n",
              "0 -2.089844 0.325684 -0.877930  1.048828  0.131714 -0.349609 -1.813477   \n",
              "1  0.875488 0.325684 -0.458252 -1.797852 -0.300293  0.584961  0.551270   \n",
              "2 -0.449463 0.325684 -0.682617  0.016266  0.026123 -0.547363  0.551270   \n",
              "\n",
              "       f_28      f_29      f_30      f_31      f_32     f_33      f_34  \\\n",
              "0  0.099243 -0.240967  1.604492  0.003637 -0.901855 0.221558  0.609863   \n",
              "1  0.806641  1.235352 -0.984863 -1.084961  3.162109 0.211060 -2.656250   \n",
              "2 -0.261475 -0.169678  0.857422 -0.098450 -0.860352 0.180176  0.609863   \n",
              "\n",
              "       f_35      f_36      f_37      f_38      f_39      f_40     f_41  \\\n",
              "0 -0.738770  2.097656 -0.914062 -0.293945 -0.037994  0.685547 0.000000   \n",
              "1 -0.177002  0.486572  1.237305 -0.447510 -0.403564 -0.769531 1.000000   \n",
              "2  0.524902 -0.400391  0.751465 -0.287598  0.568359  0.829102 0.000000   \n",
              "\n",
              "       f_42      f_43      f_44      f_45      f_46      f_47      f_48  \\\n",
              "0  0.414795 -0.469482 -1.085938 -0.106445  0.059448  0.483154  1.189453   \n",
              "1 -0.516602 -1.307617 -0.092407  0.971191 -0.069336 -0.963379 -0.840820   \n",
              "2 -0.253174 -0.235474  0.500977 -0.655762 -0.750977  0.664062  1.189453   \n",
              "\n",
              "      f_49     f_50      f_51      f_52     f_53      f_54      f_55     f_56  \\\n",
              "0 0.506836 0.754395  0.317627 -0.183228 5.164062  0.677246 -0.440674 0.631348   \n",
              "1 0.438965 0.317139  0.138550 -1.167969 0.082336  1.059570 -0.440674 0.631348   \n",
              "2 1.087891 0.859375 -0.133545 -0.183228 0.082336 -0.060181 -0.440674 0.631348   \n",
              "\n",
              "       f_57     f_58      f_59     f_60      f_61      f_62      f_63  \\\n",
              "0 -1.845703 0.227783  0.841309 0.667480 -0.854004 -0.170410 -0.119690   \n",
              "1  0.495117 1.163086  0.453369 0.631836 -0.651855 -0.170410 -0.119690   \n",
              "2 -0.026169 0.015625 -0.855957 1.052734 -0.526855 -0.170410 -0.119690   \n",
              "\n",
              "       f_64      f_65      f_66      f_67      f_68      f_69      f_70  \\\n",
              "0 -0.504883  0.662598  1.933594 -0.812500  0.072815 -0.778809 -0.553711   \n",
              "1  0.186157 -0.292480 -0.549805 -1.629883  0.902832  0.509766  0.377441   \n",
              "2  0.038177  0.309814 -0.549805  1.638672 -0.476562 -0.909180 -0.544922   \n",
              "\n",
              "       f_71      f_72      f_73     f_74     f_75      f_76      f_77  \\\n",
              "0 -0.032776 -0.619141 -1.424805 0.148315 0.257812  0.735352  0.563965   \n",
              "1  0.052094 -0.763184 -1.307617 0.148315 0.777832 -0.383301 -0.099487   \n",
              "2 -0.546387  0.163452  1.748047 0.148315 0.365234  0.342773 -0.813965   \n",
              "\n",
              "       f_78      f_79      f_80     f_81      f_82      f_83      f_84  \\\n",
              "0 -0.272217  1.190430 -0.101379 1.333984  0.191284  0.630859  1.010742   \n",
              "1 -0.119995  1.466797 -0.255371 0.136353  0.191284 -0.404541 -1.220703   \n",
              "2 -0.046417 -0.484863 -0.270264 0.136353 -1.441406 -0.079163 -0.530762   \n",
              "\n",
              "       f_85     f_86      f_87      f_88      f_89      f_90      f_91  \\\n",
              "0  0.161865 0.609375 -0.219482 -0.013069  1.505859 -1.319336  0.448242   \n",
              "1 -1.442383 1.088867 -0.479248  0.476318 -1.238281  0.139160 -1.238281   \n",
              "2  0.130981 0.221558 -0.228882  0.700195  0.023468  0.269287  0.039825   \n",
              "\n",
              "       f_92      f_93      f_94      f_95      f_96      f_97      f_98  \\\n",
              "0 -0.635254 -0.075378  1.033203 -0.664062  0.139893  0.186279  0.593262   \n",
              "1  0.277344  0.925781 -0.666016 -0.496582 -1.344727 -0.514160 -0.081726   \n",
              "2 -0.963867 -0.790039  0.693359 -0.593750  0.295166 -0.096008  0.447754   \n",
              "\n",
              "       f_99     f_100     f_101    f_102    f_103     f_104     f_105  \\\n",
              "0 -0.301514  0.666504  0.713379 1.020508 0.879883 -1.096680 -0.211060   \n",
              "1 -0.301514 -0.918945 -0.051697 1.020508 0.746582  0.911621 -0.343994   \n",
              "2 -0.301514  1.039062 -0.291748 1.020508 0.529297 -1.096680  0.150757   \n",
              "\n",
              "      f_106     f_107    f_108     f_109     f_110     f_111     f_112  \\\n",
              "0 -0.117493 -0.778809 0.065979  0.229736  0.435303  1.233398 -0.865723   \n",
              "1 -0.948242 -0.778809 0.065979 -0.229980 -0.153564 -0.722168 -0.947266   \n",
              "2 -0.074646  1.254883 0.065979  0.869141  0.518066  0.494385 -0.028580   \n",
              "\n",
              "      f_113     f_114     f_115     f_116     f_117     f_118    f_119  \\\n",
              "0  0.062347  0.382324 -1.315430  0.786621  0.770508 -0.871094 0.583496   \n",
              "1  1.321289 -0.075256  0.997070 -0.137695  0.724121 -0.722168 0.541992   \n",
              "2 -0.478271 -0.733887  0.200806 -0.174561 -0.255127  0.558594 0.586426   \n",
              "\n",
              "      f_120     f_121     f_122    f_123    f_124     f_125     f_126  \\\n",
              "0  0.115601  0.209595  0.325439 0.469238 0.000000 -0.731445 -0.249512   \n",
              "1  0.730469  0.478027 -0.662109 0.605957 0.000000  0.280518  0.781738   \n",
              "2 -2.177734 -0.765137  0.200317 0.346436 0.000000 -0.065796 -0.298340   \n",
              "\n",
              "      f_127     f_128     f_129     f_130     f_131     f_132     f_133  \\\n",
              "0 -0.050568 -1.232422 -0.790527  0.493408  0.357910 -0.381592  0.176392   \n",
              "1 -0.140503  0.324951  0.540527 -0.686523  0.388916 -1.551758 -0.662109   \n",
              "2 -0.040955 -0.875977 -0.625000  1.005859 -0.471924  0.788574 -0.547363   \n",
              "\n",
              "      f_134     f_135     f_136     f_137     f_138     f_139     f_140  \\\n",
              "0  0.748047 -0.741699  0.089661  1.080078  1.137695  1.199219  0.030609   \n",
              "1  0.312256 -1.089844  0.530762 -0.730469 -0.878906 -1.139648 -1.336914   \n",
              "2 -0.039612 -0.885254 -0.161743  0.186157  1.137695  0.052643  0.323242   \n",
              "\n",
              "      f_141    f_142     f_143     f_144    f_145     f_146     f_147  \\\n",
              "0 -0.356201 0.247803  1.395508  0.961914 0.078125 -1.163086  0.707520   \n",
              "1  0.804688 0.247803 -1.292969 -0.892578 0.078125  0.023346 -0.957031   \n",
              "2  1.156250 0.247803  0.859375  0.873047 0.078125 -0.250977 -0.418213   \n",
              "\n",
              "      f_148     f_149    f_150     f_151    f_152    f_153     f_154  \\\n",
              "0  0.256104 -0.026306 0.329102  0.196045 0.653320 0.069214  0.907715   \n",
              "1 -0.042419 -0.195312 0.329102 -0.181152 0.653320 0.069214 -0.818848   \n",
              "2  0.927246  0.648438 0.329102  0.015572 0.653320 0.069214  0.907715   \n",
              "\n",
              "      f_155     f_156     f_157    f_158     f_159     f_160     f_161  \\\n",
              "0 -0.350586 -1.170898  0.659180 0.937500  0.482910 -0.094910  0.317383   \n",
              "1  0.308838  0.894531  0.010490 0.904297  1.197266  1.052734  0.915039   \n",
              "2 -0.642578 -1.170898 -0.100586 0.122498 -0.247559  0.694336 -0.167358   \n",
              "\n",
              "      f_162     f_163     f_164     f_165     f_166     f_167     f_168  \\\n",
              "0  0.126831  0.892090 -1.199219 -0.315430  0.704102 -0.017700 -0.513184   \n",
              "1 -1.083984 -0.541992 -0.898926 -0.043518 -0.375732  0.167969  0.552246   \n",
              "2  1.062500  0.718262 -0.844238 -0.105347  0.166626 -0.375732 -0.513184   \n",
              "\n",
              "      f_169    f_170     f_171     f_172     f_173     f_174     f_175  \\\n",
              "0 -0.362549 1.000000  2.265625  0.360107  0.054474  1.639648 -1.000000   \n",
              "1  0.772949 1.000000 -1.250000  0.409912 -0.695312  1.639648 -1.000000   \n",
              "2 -0.393555 1.000000  0.596191 -0.446289 -0.115051 -0.709961 -1.000000   \n",
              "\n",
              "      f_176     f_177     f_178     f_179     f_180     f_181    f_182  \\\n",
              "0  0.876953  0.368164  0.991211 -1.224609 -1.208984 -0.879883 1.000000   \n",
              "1  0.876953 -1.523438 -0.526855 -0.071045 -0.404785  0.269531 1.000000   \n",
              "2 -1.431641 -0.577637 -0.418457 -0.515137 -0.307617 -0.283691 1.000000   \n",
              "\n",
              "     f_183     f_184     f_185    f_186     f_187     f_188     f_189  \\\n",
              "0 0.035156  0.693359  0.307129 0.143799  0.728027  1.220703 -0.939941   \n",
              "1 0.035156 -0.309326 -1.067383 1.087891 -1.145508 -0.025330 -0.398438   \n",
              "2 0.035156 -0.393799  0.288086 0.366455  0.103333 -0.098328  0.133911   \n",
              "\n",
              "      f_190    f_191     f_192     f_193     f_194     f_195     f_196  \\\n",
              "0 -0.106934 0.000000 -0.569336  0.187866 -0.386475 -0.452393  0.269775   \n",
              "1 -1.173828 0.427002  0.043945  0.510742  1.408203 -0.718750  2.076172   \n",
              "2  0.212280 0.384521  0.501465 -0.339355  0.010094 -0.007168 -1.117188   \n",
              "\n",
              "      f_197     f_198     f_199    f_200     f_201     f_202    f_203  \\\n",
              "0 -0.565430 -0.262207 -1.473633 0.000000  0.428223  1.740234 0.941406   \n",
              "1 -0.507812  0.942383  1.028320 0.000000  1.050781 -1.009766 0.480713   \n",
              "2 -0.564941  0.672852 -0.775879 0.000000 -0.070007  0.883301 0.579102   \n",
              "\n",
              "      f_204     f_205     f_206     f_207     f_208     f_209     f_210  \\\n",
              "0 -0.729980 -0.533203 -0.983398 -0.043152 -0.225952 -0.008301 -0.447998   \n",
              "1 -1.363281 -0.358398  0.084900 -0.012634 -1.496094 -1.260742 -0.452148   \n",
              "2  0.942871 -0.793457 -0.955078  0.131836 -0.546875  0.905273 -0.452148   \n",
              "\n",
              "      f_211     f_212     f_213     f_214     f_215     f_216    f_217  \\\n",
              "0  0.551270 -0.153076 -2.292969  0.186646 -0.443115  0.121216 0.787598   \n",
              "1 -0.253418 -1.107422  0.492188  0.727051  0.400635 -2.302734 1.443359   \n",
              "2  0.675293 -0.036041 -1.169922 -0.167603 -0.274414  0.114014 0.103210   \n",
              "\n",
              "      f_218     f_219     f_220     f_221     f_222     f_223     f_224  \\\n",
              "0  1.996094 -1.286133 -0.157227  1.019531  0.693359  0.797363 -0.192627   \n",
              "1 -0.231445  0.777344  1.995117 -0.593750  0.737793 -0.841797 -0.191528   \n",
              "2  0.071045 -1.286133 -0.407959  0.137207 -0.399414  0.335693 -0.149292   \n",
              "\n",
              "     f_225    f_226     f_227     f_228    f_229     f_230     f_231  \\\n",
              "0 0.222778 0.921387 -0.171387  0.021652 1.153320  0.689941  3.251953   \n",
              "1 0.222778 0.872559  0.611328 -0.113159 1.153320  0.866211 -0.269775   \n",
              "2 0.222778 0.156128 -0.171387  0.258301 1.153320 -0.964355 -0.269775   \n",
              "\n",
              "      f_232     f_233     f_234     f_235     f_236     f_237     f_238  \\\n",
              "0  0.992188 -0.779785 -0.546387 -0.379150  1.896484 -0.732422 -0.113770   \n",
              "1 -0.078003 -0.332764 -0.546387 -0.678711 -0.434082 -0.584473  0.332031   \n",
              "2 -0.654297  0.180542 -1.220703  0.457520 -0.461182 -0.976562  0.147339   \n",
              "\n",
              "      f_239     f_240    f_241     f_242     f_243     f_244     f_245  \\\n",
              "0  1.127930 -0.007927 0.122314  0.444580  0.485840 -2.302734  0.392822   \n",
              "1 -0.646973 -0.176514 0.122314 -0.068176 -0.868164  0.844727  0.863281   \n",
              "2  0.060364 -0.271729 0.122314  1.450195  1.163086  0.402588 -0.101135   \n",
              "\n",
              "     f_246     f_247     f_248     f_249     f_250     f_251    f_252  \\\n",
              "0 0.000000 -0.779297 -0.893555  0.055939  0.201416 -0.338135 1.278320   \n",
              "1 1.179688 -0.049469  0.484863 -0.050537 -0.491943 -0.164429 0.133667   \n",
              "2 0.000000  0.019119  0.523438 -0.005413 -0.092407 -0.001884 0.259277   \n",
              "\n",
              "      f_253     f_254     f_255     f_256     f_257     f_258     f_259  \\\n",
              "0  1.367188  0.525391 -0.055664  0.145264  0.346924 -0.824219 -1.306641   \n",
              "1 -0.952637 -0.387451  0.090637 -0.811035 -0.821289 -0.546875 -0.067871   \n",
              "2  0.507324  0.202515 -0.370850  0.828125  0.257080  0.027908 -0.662598   \n",
              "\n",
              "      f_260     f_261     f_262     f_263     f_264     f_265     f_266  \\\n",
              "0 -1.158203  0.709473 -0.031891 -1.020508 -1.291016  0.038666  0.187134   \n",
              "1 -0.767090 -0.015457 -0.158325  0.980469  0.799316  0.798340 -0.633301   \n",
              "2  1.066406 -0.528320  0.189453 -1.020508  0.169678 -0.911133 -0.222046   \n",
              "\n",
              "      f_267     f_268     f_269     f_270     f_271    f_272     f_273  \\\n",
              "0 -0.680176  0.900391 -0.924805 -1.057617 -0.167114 0.000000  1.281250   \n",
              "1  0.779785  0.171265  1.166016  0.590820  0.118530 0.000000 -0.650879   \n",
              "2  0.536621 -0.161743 -0.114319  0.433350 -0.207153 0.000000  0.098938   \n",
              "\n",
              "      f_274     f_275     f_276     f_277     f_278     f_279     f_280  \\\n",
              "0  0.258789 -0.237915 -0.742188 -0.324707  0.992676  0.961426 -0.025604   \n",
              "1  0.852051  0.086182  1.135742  0.299072 -1.583008 -0.481934  0.532227   \n",
              "2 -0.725098 -0.388184  0.062622  0.260254  0.980957  0.899414 -0.315430   \n",
              "\n",
              "      f_281     f_282     f_283     f_284     f_285     f_286     f_287  \\\n",
              "0 -0.006260  0.473633  0.040131  0.453613 -1.597656  0.301758  0.157471   \n",
              "1  0.226685 -0.894531 -0.514648 -1.000000  0.884277 -0.557617 -0.875488   \n",
              "2  0.150146  0.245605 -1.429688 -1.000000 -0.033508 -0.147095 -0.087524   \n",
              "\n",
              "      f_288     f_289     f_290     f_291     f_292     f_293     f_294  \\\n",
              "0  0.416748  1.505859  0.365967 -1.095703  0.200073  0.819336  0.941406   \n",
              "1 -0.156128  0.537109 -0.154175  0.912598 -0.734375  0.819336  0.941406   \n",
              "2  0.098450 -0.528809 -0.138062  0.912598 -0.551758 -1.220703 -1.060547   \n",
              "\n",
              "      f_295     f_296     f_297     f_298     f_299  \n",
              "0 -0.086792 -1.086914 -1.044922 -0.287598  0.321533  \n",
              "1 -0.387695 -1.086914 -0.929688 -0.974121 -0.343506  \n",
              "2 -0.219116 -1.086914 -0.612305 -0.113953  0.243652  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_drop = []\n",
        "for i in df.columns.tolist():\n",
        "  if i not in data_columns:\n",
        "    to_drop.append(i)\n",
        "\n",
        "df_train = df.drop(to_drop, axis=1)\n",
        "df_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ZoJboC7oRStC",
        "outputId": "5c6d2253-4b69-4f60-f63c-0c99d56aeb42"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6a7f8b6-07ab-4e7b-811b-49c8e87b2fef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.300875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.231040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.568807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6a7f8b6-07ab-4e7b-811b-49c8e87b2fef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6a7f8b6-07ab-4e7b-811b-49c8e87b2fef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6a7f8b6-07ab-4e7b-811b-49c8e87b2fef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "0 -0.300875\n",
              "1 -0.231040\n",
              "2  0.568807"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_investment_id = df[\"investment_id\"]\n",
        "integer_lookup_layer = tf.keras.layers.IntegerLookup()\n",
        "integer_lookup_layer.adapt(pd.DataFrame({\"investment_id\": list(df_investment_id.unique())}))\n",
        "\n",
        "df_target = pd.DataFrame(df[\"target\"])\n",
        "df_target.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jWs-WHr8hcgs"
      },
      "outputs": [],
      "source": [
        "def create_model_1():\n",
        "  activation_func = tf.keras.activations.relu\n",
        "  investment_id_input = tf.keras.layers.Input(shape=(1,))\n",
        "  x_input = tf.keras.layers.Input(shape=(len(data_columns),))\n",
        "  x = tf.keras.layers.Dense(128, activation=activation_func)(x_input)\n",
        "  x = tf.keras.layers.Dense(128, activation=activation_func)(x)\n",
        "\n",
        "  investment_id_x = integer_lookup_layer(investment_id_input)\n",
        "  investment_id_x = tf.keras.layers.Embedding(len(df_investment_id.unique()) + 1, 32, input_length=1)(investment_id_x) # shape (None, 1, 32)\n",
        "  investment_id_x = tf.keras.layers.Reshape((-1, ))(investment_id_x) # shape (None, 32)\n",
        "  investment_id_x = tf.keras.layers.Dense(128, activation=activation_func)(investment_id_x)\n",
        "  investment_id_x = tf.keras.layers.Dense(128, activation=activation_func)(investment_id_x)\n",
        "\n",
        "  concat = tf.keras.layers.Concatenate(axis=1)([investment_id_x, x])\n",
        "  concat = tf.keras.layers.Dense(128, activation=activation_func)(concat)\n",
        "  concat = tf.keras.layers.Dense(32, activation=activation_func)(concat)\n",
        "  output = tf.keras.layers.Dense(1)(concat)\n",
        "\n",
        "  model = Model(inputs=[investment_id_input, x_input], outputs=[output])\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(), \n",
        "    loss=tf.keras.losses.MeanSquaredError(), \n",
        "    metrics=tf.keras.metrics.RootMeanSquaredError()\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NpwE6SIhdhN",
        "outputId": "027e5f40-5ba3-41af-cc24-133b1c4897c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2081/2084 [============================>.] - ETA: 0s - loss: 0.8398 - root_mean_squared_error: 0.9164INFO:tensorflow:Assets written to: model_split_0/assets\n",
            "2084/2084 [==============================] - 17s 8ms/step - loss: 0.8393 - root_mean_squared_error: 0.9161 - val_loss: 0.9624 - val_root_mean_squared_error: 0.9810\n",
            "Epoch 2/5\n",
            "2076/2084 [============================>.] - ETA: 0s - loss: 0.8233 - root_mean_squared_error: 0.9073INFO:tensorflow:Assets written to: model_split_0/assets\n",
            "2084/2084 [==============================] - 16s 8ms/step - loss: 0.8223 - root_mean_squared_error: 0.9068 - val_loss: 0.9551 - val_root_mean_squared_error: 0.9773\n",
            "Epoch 3/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.7680 - root_mean_squared_error: 0.8763 - val_loss: 1.0502 - val_root_mean_squared_error: 1.0248\n",
            "Epoch 4/5\n",
            "2084/2084 [==============================] - 14s 7ms/step - loss: 0.7318 - root_mean_squared_error: 0.8555 - val_loss: 1.1526 - val_root_mean_squared_error: 1.0736\n",
            "Epoch 5/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.7031 - root_mean_squared_error: 0.8385 - val_loss: 1.1872 - val_root_mean_squared_error: 1.0896\n",
            "Epoch 1/5\n",
            "2083/2084 [============================>.] - ETA: 0s - loss: 0.8338 - root_mean_squared_error: 0.9131INFO:tensorflow:Assets written to: model_split_1/assets\n",
            "2084/2084 [==============================] - 16s 7ms/step - loss: 0.8338 - root_mean_squared_error: 0.9131 - val_loss: 1.0220 - val_root_mean_squared_error: 1.0109\n",
            "Epoch 2/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.8218 - root_mean_squared_error: 0.9065 - val_loss: 1.1057 - val_root_mean_squared_error: 1.0515\n",
            "Epoch 3/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.7819 - root_mean_squared_error: 0.8843 - val_loss: 1.1115 - val_root_mean_squared_error: 1.0543\n",
            "Epoch 4/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.7454 - root_mean_squared_error: 0.8634 - val_loss: 1.3783 - val_root_mean_squared_error: 1.1740\n",
            "Epoch 5/5\n",
            "2084/2084 [==============================] - 20s 10ms/step - loss: 0.7198 - root_mean_squared_error: 0.8484 - val_loss: 1.6216 - val_root_mean_squared_error: 1.2734\n",
            "Epoch 1/5\n",
            "2078/2084 [============================>.] - ETA: 0s - loss: 0.8220 - root_mean_squared_error: 0.9066INFO:tensorflow:Assets written to: model_split_2/assets\n",
            "2084/2084 [==============================] - 16s 7ms/step - loss: 0.8231 - root_mean_squared_error: 0.9073 - val_loss: 0.9494 - val_root_mean_squared_error: 0.9744\n",
            "Epoch 2/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.8027 - root_mean_squared_error: 0.8960 - val_loss: 1.0062 - val_root_mean_squared_error: 1.0031\n",
            "Epoch 3/5\n",
            "2084/2084 [==============================] - 13s 6ms/step - loss: 0.7492 - root_mean_squared_error: 0.8655 - val_loss: 0.9953 - val_root_mean_squared_error: 0.9977\n",
            "Epoch 4/5\n",
            "2084/2084 [==============================] - 14s 6ms/step - loss: 0.7123 - root_mean_squared_error: 0.8440 - val_loss: 1.1186 - val_root_mean_squared_error: 1.0576\n",
            "Epoch 5/5\n",
            "2084/2084 [==============================] - 14s 6ms/step - loss: 0.6854 - root_mean_squared_error: 0.8279 - val_loss: 1.1633 - val_root_mean_squared_error: 1.0786\n"
          ]
        }
      ],
      "source": [
        "def create_ds(X: pd.DataFrame, investment_id: pd.DataFrame,  y: pd.DataFrame):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(((investment_id, X), y[\"target\"]))\n",
        "  ds = ds.shuffle(128)\n",
        "  ds = ds.batch(32)\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "epochs = 5\n",
        "random_state = 1\n",
        "n_splits = 3\n",
        "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "split = kfold.split(df_train[data_columns], df_investment_id)\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(split):\n",
        "  X_train, X_test = df_train.iloc[train_index], df_train.iloc[test_index]\n",
        "  y_train, y_test = df_target.iloc[train_index], df_target.iloc[test_index]\n",
        "  investment_id_train, investment_id_test = df_investment_id.iloc[train_index], df_investment_id.iloc[test_index]\n",
        "  ds_train = create_ds(X_train, investment_id_train, y_train)\n",
        "  ds_test = create_ds(X_test, investment_id_test, y_test)\n",
        "  model = create_model_1()\n",
        "  model.fit(ds_train, epochs=epochs, validation_data=ds_test, callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath = f\"model_split_{i}\",\n",
        "      save_best_only=True,\n",
        "    )\n",
        "  ])\n",
        "\n",
        "  del ds_train, ds_test, model\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AFdGWKzpEdyP"
      },
      "outputs": [],
      "source": [
        "def predict(models, ds):\n",
        "  predictions = []\n",
        "  for model in models:\n",
        "    predictions.append(model.predict(ds))\n",
        "  return np.mean(predictions, axis=0)\n",
        "\n",
        "def create_predict_ds(X: pd.DataFrame, investment_id: pd.DataFrame):\n",
        "  ds = tf.data.Dataset.from_tensor_slices(((investment_id, X)))\n",
        "  ds = ds.batch(32)\n",
        "  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "models = []\n",
        "\n",
        "for i in range(n_splits):\n",
        "  models.append(tf.keras.models.load_model(f\"model_split_{i}\"))\n",
        "\n",
        "df_test = None # insert df here\n",
        "ds_test = create_predict_ds = create_predict_ds(df_test)\n",
        "predict(models, ds_test)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ubiquant_market_prediction_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
